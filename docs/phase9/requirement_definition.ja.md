# Phase 9: OpenAI分析の最適化 要件定義・仕様案

## 1. 背景と課題
現在、`ScoutRun` ごとに収集されたすべてのチャンネルに対して個別に `Analyzer` が `call_gpt` を実行している。
- **課題1**: チャンネル数に比例してAPIコストが増大する。
- **課題2**: 明らかにターゲット外のチャンネル（活動停止中、登録者数が極端に少ないなど）も分析対象となっている。
- **課題3**: 1件ずつのリクエストにより、レートリミットや処理時間に影響が出る。

## 2. 改善アプローチ

### 2.1 数値ベースのフィルタリング（一次スクリーニング）
OpenAIを呼び出す前に、DBに保存された `scout_snapshots` の数値を用いて分析対象を絞り込む。

**推奨されるスクリーニング基準例:**
- **アクティビティ**: `upload_freq_days` が一定以下（例：30日以内に投稿がある、または1年以内に12本以上）。
- **影響力**: `subscriber_count` が一定範囲内（例：500人以上）。
- **成長性**: `view_count` や登録者の伸び（前回比）がある程度見込めるもの。
- **除外設定**: すでに「分析済みかつ低スコア（Normal）」だったものは、一定期間再分析しない。

### 2.2 分析モードの導入
実行時の `config` により、以下のモードを選択可能にする。

| モード | 説明 |
| :--- | :--- |
| `Full` | 全件分析（現状維持）。精度を最優先する場合。 |
| `Smart` | スクリーニング通過者のみ個別に分析（推奨）。コストと精度のバランス。 |
| `Aggregated` | 複数件を1回のプロンプトにまとめ、概要のみ生成。最安コスト。 |

### 2.3 一括分析（Aggregated Analysis）のプロンプト設計
1回のAPIコールで5〜10件程度の「概要」と「優先度」のみを抽出する形式。

**プロンプト案:**
> 以下の10件のチャンネルデータを分析し、スカウト優先度が高い順に3件選び、その理由と推薦オファーを簡潔に回答してください。
> 回答形式: JSON (fields: recommendations[ {rank, name, id, score_preview, reason, offer} ])

## 3. 具体的な処理フロー案
1. `Orchestrator` が `collector.collect_multiple_sources` を実行。
2. `Orchestrator` がDBから取得した `snapshots` をフィルタリング関数に渡す。
3. フィルタリングを通過した `entity_id` のリストを作成。
4. `Analyzer` がリスト対象のみを `analyze_batch` で処理。

## 4. 設定項目の追加
`.env` または `config.py` に以下の設定を追加検討。
- `MIN_SUBSCRIBERS`: スクリーニング対象の下限
- `RE_ANALYZE_DAYS`: 低スコアだった場合に再分析をスキップする日数
- `ANALYSIS_MODE`: デフォルトの分析モード (smart / full / aggregated)
